{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f59ace",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "753a0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f95f4",
   "metadata": {},
   "source": [
    "# Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e478e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current working directory instead\n",
    "base_path = os.getcwd()\n",
    "data_source_dir = os.path.abspath(os.path.join(base_path, \"..\", \"..\", \"A. Data Source\", \"A.2. SSKI (Bank Indonesia)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a983a2c",
   "metadata": {},
   "source": [
    "# Additional Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc0c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sheet_15a_or_16a(file_path):\n",
    "    try:\n",
    "        # Get all sheet names\n",
    "        sheet_names = pd.ExcelFile(file_path).sheet_names\n",
    "\n",
    "        # Select the appropriate sheet\n",
    "        target_sheet = None\n",
    "        if '15a' in sheet_names:\n",
    "            target_sheet = '15a'\n",
    "        elif '16a' in sheet_names:\n",
    "            target_sheet = '16a'\n",
    "\n",
    "        if target_sheet:\n",
    "            df = pd.read_excel(file_path, sheet_name=target_sheet)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"No sheet '15a' or '16a' found in {file_path}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268753a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase and remove all spaces.\"\"\"\n",
    "    return str(text).lower().replace(\" \", \"\")\n",
    "\n",
    "def merge_rows(df, merge_list, col_index=1):\n",
    "    # Normalize the merge_list\n",
    "    normalized_list = [normalize_text(item) for item in merge_list]\n",
    "\n",
    "    rows_to_drop = []\n",
    "    for i in range(len(df) - 1):\n",
    "        current_val = normalize_text(df.iloc[i, col_index])\n",
    "\n",
    "        if current_val in normalized_list:\n",
    "            # Merge current row with the next row (column by column)\n",
    "            for col in df.columns:\n",
    "                val1 = df.at[i, col]\n",
    "                val2 = df.at[i + 1, col]\n",
    "\n",
    "                # Convert nulls to empty string, others to string\n",
    "                str1 = \"\" if pd.isna(val1) else str(val1)\n",
    "                str2 = \"\" if pd.isna(val2) else str(val2)\n",
    "\n",
    "                # Merge with a space only if both are non-empty\n",
    "                if str1 and str2:\n",
    "                    merged = str1 + \" \" + str2\n",
    "                else:\n",
    "                    merged = str1 + str2  # One of them is empty\n",
    "\n",
    "                df.at[i, col] = merged\n",
    "\n",
    "            rows_to_drop.append(i + 1)\n",
    "\n",
    "    df = df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc33ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_dataframe_target(df:pd.DataFrame, col_index:int, target_value:str)-> pd.DataFrame :\n",
    "    col_name = df.columns[col_index]\n",
    "\n",
    "    # print(f\"Columns name to searched and cut : {col_name}\")\n",
    "    standardized_target = target_value.lower().replace(' ', '')\n",
    "\n",
    "    # Standardize column 1 values\n",
    "    standardized_col = df[col_name].str.lower().str.replace(' ', '', regex=False)\n",
    "\n",
    "    # Find first match\n",
    "    start_index = df[standardized_col == standardized_target].index.min()\n",
    "                                                                                                           \n",
    "    # Filter rows from that index down\n",
    "    if(start_index >= 3) :\n",
    "        filtered_df = df.loc[start_index:]\n",
    "    else :\n",
    "        filtered_df = df.loc[0:]\n",
    "\n",
    "    return(filtered_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1189ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_q_strings_inplace(df: pd.DataFrame):\n",
    "    first_row = df.iloc[0].tolist()  # Make a copy to iterate safely\n",
    "\n",
    "    for idx, val in enumerate(first_row):\n",
    "        if isinstance(val, str) and val.startswith('Q'):\n",
    "            # Search leftward\n",
    "            for left_idx in range(idx - 1, -1, -1):\n",
    "                left_val = str(first_row[left_idx])\n",
    "                if re.match(r'^\\d', left_val):  # Starts with digit\n",
    "                    digits = re.findall(r'\\d', left_val)\n",
    "                    if len(digits) >= 4:\n",
    "                        left_number = ''.join(digits[:4])\n",
    "                        new_val = f\"{left_number} {val}\"\n",
    "                        df.iat[0, idx] = new_val  # Update value in-place\n",
    "                    break  # Stop after first match\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "227aff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe_and_trim_nulls(df):\n",
    "    # Step 1: Remove first and last two columns\n",
    "    df = df.iloc[:, 1:-2]\n",
    "\n",
    "    # Step 2: Reset column index\n",
    "    df.columns = range(df.shape[1])\n",
    "\n",
    "    # Step 3: Set first cell to \"KOMPONEN\"\n",
    "    df.iat[0, 0] = \"KOMPONEN\"\n",
    "\n",
    "    # Step 4: Always remove last row if:\n",
    "    # - The entire row is null, or\n",
    "    # - The value in first column is null\n",
    "    while df.shape[0] > 0:\n",
    "        last_idx = df.index[-1]\n",
    "        if df.iloc[last_idx].isnull().all() or pd.isna(df.iat[last_idx, 0]):\n",
    "            df = df.drop(index=last_idx)\n",
    "        else:\n",
    "            break  # Stop when a valid last row is found\n",
    "\n",
    "    # Step 5: Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1739e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_section_headers(df:pd.DataFrame, search_values:list, new_col_name:str, target_col_index:int=0):\n",
    "    # Step 1: Insert new column at the beginning\n",
    "    df.insert(0, new_col_name, None)\n",
    "\n",
    "    # Step 2: Normalize search values once\n",
    "    normalized_search = [normalize_text(val) for val in search_values]\n",
    "\n",
    "    # Step 3: Convert column to list for processing\n",
    "    col_values = df.iloc[:, target_col_index + 1].tolist()  # +1 because of inserted column\n",
    "\n",
    "    # Step 4: Track index manually because we'll be deleting rows\n",
    "    i = 0\n",
    "    while i < len(col_values):\n",
    "        val = col_values[i]\n",
    "        norm_val = normalize_text(val)\n",
    "\n",
    "        if norm_val in normalized_search:\n",
    "            header = val  # Keep original text for tagging\n",
    "            start_idx = i\n",
    "\n",
    "            # Remove the header row\n",
    "            df = df.drop(index=start_idx)\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # Rebuild col_values after drop\n",
    "            col_values = df.iloc[:, target_col_index + 1].tolist()\n",
    "\n",
    "            # Fill new_col_name from start_idx until next header or end\n",
    "            end_idx = start_idx\n",
    "            while end_idx < len(col_values) and normalize_text(col_values[end_idx]) not in normalized_search:\n",
    "                df.at[end_idx, new_col_name] = header\n",
    "                end_idx += 1\n",
    "\n",
    "            # Start next search at end_idx\n",
    "            i = end_idx\n",
    "            col_values = df.iloc[:, target_col_index + 1].tolist()\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d643c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_tag_section_by_null_above(df: pd.DataFrame, new_col_name: str, target_col_index: int = 1):\n",
    "    # Step 1: Insert the new column at position 1 (second column)\n",
    "    df.insert(1, new_col_name, None)\n",
    "\n",
    "    # Step 2: Prepare tracking\n",
    "    i = 1  # Start from second row since we'll compare with row - 1\n",
    "    current_tag = None\n",
    "\n",
    "    while i < len(df):\n",
    "        current_val = df.iat[i, target_col_index + 1]  # +1 because of inserted column\n",
    "        prev_val = df.iat[i - 1, target_col_index + 1]\n",
    "\n",
    "        if pd.notna(current_val) and pd.isna(prev_val):\n",
    "            # New section detected\n",
    "\n",
    "            # Store the tag (original text)\n",
    "            current_tag = current_val\n",
    "\n",
    "            # Remove both tag row and null row above it\n",
    "            df = df.drop(index=[i - 1, i])\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # Recalculate total length\n",
    "            i -= 2  # Step back to safely continue from the right index\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "        else:\n",
    "            if current_tag:\n",
    "                df.iat[i, 1] = current_tag  # Set the tag into the new column\n",
    "            i += 1\n",
    "\n",
    "    # Fill the last part of the dataframe with the final tag\n",
    "    for j in range(i, len(df)):\n",
    "        if current_tag:\n",
    "            df.iat[j, 1] = current_tag\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0706dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_tag_section_by_null_right(df: pd.DataFrame, new_col_name: str, target_col_index: int = 2):\n",
    "    # Step 1: Insert new column at position 2 (third column)\n",
    "    df.insert(target_col_index, new_col_name, None)\n",
    "\n",
    "    current_tag = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(df):\n",
    "        current_val = df.iat[i, target_col_index + 1]      # Value in the tag column (newly inserted)\n",
    "        right_val = df.iat[i, target_col_index + 2]     # Value in the original \"right\" column (index 3 originally)\n",
    "\n",
    "        if pd.notna(current_val) and pd.isna(right_val):\n",
    "            # Treat this row as a tag\n",
    "            current_tag = current_val\n",
    "\n",
    "            # Remove the tag row\n",
    "            df = df.drop(index=i)\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            # No increment â€” stay on the same row after drop\n",
    "            continue\n",
    "        else:\n",
    "            if current_tag:\n",
    "                df.iat[i, target_col_index] = current_tag\n",
    "        i += 1\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5883d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionally_clear_ket_data_level_3_per_row(df: pd.DataFrame, check_str : str) -> pd.DataFrame:\n",
    "    if 'ket_data_level_3' not in df.columns:\n",
    "        return df  # Do nothing if the column doesn't exist\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        val = df.iat[i, 0]  # Value in column index 0\n",
    "        if normalize_text(val) != normalize_text(check_str):\n",
    "            df.at[i, 'ket_data_level_3'] = None  # or use np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55225302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_from_first_row(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Step 1: Get the current column names\n",
    "    current_cols = df.columns.tolist()\n",
    "\n",
    "    # Step 2: Get the first row as new names (for columns index 3 onward)\n",
    "    new_names = df.iloc[0, 3:].tolist()\n",
    "\n",
    "    # Step 3: Combine fixed names (first 3) + new names from first row\n",
    "    updated_cols = current_cols[:3] + new_names\n",
    "\n",
    "    # Step 4: Assign new column names\n",
    "    df.columns = updated_cols\n",
    "\n",
    "    # Step 5: Drop the first row\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aec3900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end_df_processing(df:pd.DataFrame) -> pd.DataFrame :\n",
    "    merge_key_list = [\n",
    "        \"KOMPONEN\"\n",
    "    ]\n",
    "    \n",
    "    target_value = \"KOMPONEN\"\n",
    "\n",
    "    value_list = [\n",
    "        \"RASIO KINERJA KEUANGAN\",\n",
    "        \"DATA KINERJA KEUANGAN\",\n",
    "        \"INDIKATOR HASIL SURVEI 3)\"\n",
    "    ]\n",
    "\n",
    "    process_df_0 = merge_rows(df, merge_key_list, 0)\n",
    "    process_df_1 = cut_dataframe_target(process_df_0.copy(), 0, target_value)\n",
    "    process_df_2 = process_q_strings_inplace(process_df_1.copy())\n",
    "    process_df_3 = clean_dataframe_and_trim_nulls(process_df_2.copy())\n",
    "    process_df_4 = tag_section_headers(process_df_3.copy(), value_list, \"ket_data_level_1\")\n",
    "    process_df_5 = auto_tag_section_by_null_above(process_df_4.copy(), \"ket_data_level_2\")\n",
    "    process_df_6 = auto_tag_section_by_null_right(process_df_5.copy(), \"ket_data_level_3\")\n",
    "    process_df_7 = conditionally_clear_ket_data_level_3_per_row(process_df_6.copy(), \"RASIO KINERJA KEUANGAN\")\n",
    "    process_df_8 = rename_columns_from_first_row(process_df_7.copy())\n",
    "\n",
    "    return(process_df_8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c5807",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de961555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found excel file : SSKI_DESEMBER_2022.xlsx\n",
      "Found excel file : SSKI_DESEMBER_2023.xlsx\n",
      "Found excel file : SSKI_DESEMBER_2024.xlsx\n",
      "Found excel file : SSKI_JUNI 2025.xlsx\n",
      "Found excel file : SSKI_JUNI_2022.xlsx\n",
      "Found excel file : SSKI_JUNI_2023.xlsx\n",
      "Found excel file : SSKI_JUNI_2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "# Loop through all child folders\n",
    "for folder in os.listdir(data_source_dir):\n",
    "    folder_path = os.path.join(data_source_dir, folder)\n",
    "    \n",
    "    # Only process if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.xlsx'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                try:\n",
    "                    print(f\"Found excel file : {file}\")\n",
    "                    df = read_sheet_15a_or_16a(file_path)\n",
    "                    key = os.path.splitext(file)[0]  # Get filename without extension\n",
    "                    data_dict[key] = df\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to read {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a03bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_backup = data_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed5a6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data_dict_backup.copy()\n",
    "\n",
    "merge_key_list = [\n",
    "    \"KOMPONEN\"\n",
    "]\n",
    "\n",
    "for key in data_dict.keys() :\n",
    "    df = data_dict[key]\n",
    "    new_df = end_to_end_df_processing(df)\n",
    "    data_dict[key] = new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
